## Кластеризация и методы снижения размерности
В рамках этого дня я узнал, что такое обучение без учителя, и научился использовать различные методы кластеризации.

В машинном обучении есть методы, которые позволяют решать задачи обучения "без учителя". Это такой класс задач, когда у нас нет четких ответов для объектов и, больше того, у нас даже нет обучающей выборки. Самая часто встречаемая задача этого класса - кластеризация. Здесь мы имеем набор объектов с их характеристиками (признаками), но у нас нет информации, каким классам они принадлежат или в какое числовое значение они должны отображаться. Нам просто нужно разделить их на группы так, чтобы похожие объекты оказались в одном кластере, а различные объекты - в разных кластерах. А вот принцип, по которому мы будем считать объекты похожими, нам нужно определить самостоятельно.

Изучил некоторые методы кластеризации выборок объектов, а также познакомился с методами снижения размерности признакового пространства. Последняя группа методов может быть нам полезна, когда объекты описываются очень большим количеством признаков, и нам тяжело обрабатывать их все. Здесь наша задача - описать объекты меньшим количеством признаков, но так, чтобы относительные расстояния между объектами в старом признаковом пространстве как можно точнее сохранились и в новом.

### Цели

 Научимся кластеризовать выборку с использованием библиотеки sklearn, а также научиться применять методы понижения размерности признакового пространства для упрощения решения задач машинного обучения.


### Задание

Работа с неразмеченными данными. 

Что нужно сделать:
1. Провести кластеризацию данных из прилагаемого файла. Выбрать количество кластеров для выборки по методам локтя, silhouette_score, calinski_harabasz_score и davies_bouldin_score. Обучить KMeans с разбиением на два кластера, провести оценку результата с помощью classification_report. Оценить результат кластеризации с помощью функции metrics4() и заполните соответствующий столбец таблицы итогов кластеризации m4.
2. Обучить общую модель агломеративной кластеризации. Выбрать количество кластеров по дендрограмме. Обучить модель агломеративной кластеризации для двух кластеров. Оценить качество кластеризации и записать результат в таблицу итогов.
3. Обучить модель PCA для 6 главных компонент. Визуализировать сохраненную дисперсию. Определить количество главных компонент, сохраняющих не менее 90% дисперсии. Обучить модель для двух главных компонент и визуализировать данные.
4. Визуализировать данные с помощью метода t-SNE при различных значениях perplexity.
5. Написать функцию add_a_ov, которая исправляет ошибку 19-го кластера. Внедрить эту функцию в функцию viz_dbscan. Обучить модель DBSCAN с параметрами по умолчанию и визуализировать результат. Подберите гиперпараметр eps. Провести визуализацию зависимости количества кластеров от параметра eps. Обучить модель DBSCAN с таким параметром eps, чтобы получить разбиение на два кластера. Визуализировать результат. Проанализировать соответствие полученных кластеров классам. Оценить качество кластеризации и записать результат в таблицу. Сделать выводы по всем методам кластеризации.
