{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBJxV7kqcxhz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from IPython.core.display import Image, display\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "import pylab as pl\n",
        "import re\n",
        "import codecs\n",
        "import nltk\n",
        "!pip install pymorphy2\n",
        "import pymorphy2\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "%pylab inline\n",
        "pylab.rcParams['figure.figsize'] = (15,10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzHcJiO_cxh1"
      },
      "source": [
        "---\n",
        "\n",
        "## Семантический анализ твитов\n",
        "\n",
        "Сегодня мы построим классификатор, который будет разделять текст на позитивные и негативные высказывания. Для этого мы воспользуемся уже размеченной базой.\n",
        "Загрузим данные для анализа"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SvWtVri3t5fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive  # если вы выполняете код из среды Google Colab, нужно подключить свой гугл-диск,\n",
        "drive.mount('/content/drive')   # чтобы можно было оттуда считать файл с данными для этого задания"
      ],
      "metadata": {
        "id": "7jwYGt9PtvyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9xDxvzacxh3"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/data/tweets_example.xlsx')\n",
        "df.loc[16:25]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LPhxl7Ucxh3"
      },
      "source": [
        "---\n",
        "\n",
        "Все колонки таблицы могут содержать информацию о тональности твита, но мы будем ориентироваться исключительно на текст и на столбец отнесения к классу positiv.\n",
        "Заменим значение -1 в колонке positive на 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VBRASFNcxh4"
      },
      "outputs": [],
      "source": [
        "df.positive[df.positive==-1]=0\n",
        "df.loc[16:25]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6guuzB4cxh4"
      },
      "source": [
        "-----\n",
        "\n",
        "# Задание 1\n",
        "\n",
        "1. С помощью *pd.read_csv()* загрузите датафреймы positive.csv и negative.csv (обратите внимание, что исходные таблицы не содержат наименования столбцов и на первой строке располагаются данные. Файлы расположены в папке datasets);\n",
        "2. Объедините датафреймы с помощью *pd.concat()* в один датафрейм;\n",
        "3. Убедитесь, что в новом датафрейме индексация сквозная и без повторов;\n",
        "4. Переименуйте столбцы датафрейма (столбцы полностью соответствуют примеру);\n",
        "5. Выведите информацию об общем количестве полученных твитов, сколько из них негативных, сколько позитивных.\n",
        "\n",
        "-----"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pos = pd.read_csv('/content/drive/MyDrive/data/positive.csv', sep=';', names=['id', 'date', 'name', 'text', 'positive', 'rep', 'rtv', 'fav', 'total_count', 'fol', 'friends', 'list_count'])\n",
        "df_neg = pd.read_csv('/content/drive/MyDrive/data/negative.csv', sep=';', names=['id', 'date', 'name', 'text', 'positive', 'rep', 'rtv', 'fav', 'total_count', 'fol', 'friends', 'list_count'])\n",
        "df_neg.positive[df_neg.positive==-1]=0\n",
        "\n",
        "df_all = pd.concat([df_pos, df_neg], ignore_index=True)\n",
        "df_all.id.duplicated()\n",
        "\n",
        "print ('All tweets count : ', df_all['positive'].count())\n",
        "\n",
        "count = (df_all['positive'] == 1).sum()\n",
        "print('Positive tweets count : ', count)\n",
        "\n",
        "count_neg = (df_all['positive'] == 0).sum()\n",
        "print('Negative tweets count : ', count_neg)\n",
        "\n",
        "df_all['text'] = df_all['text'].str.replace('ё','е')\n",
        "df_all['text'] = df_all['text'].str.replace('Ё','Е')\n",
        "df_all[7:8]"
      ],
      "metadata": {
        "id": "JMvxnlynalyo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ6Uu0l_cxh5"
      },
      "source": [
        "### Очистка и предобработка данных\n",
        "\n",
        "Перед разработкой классификатора нам необходимо очистить и предобработать данные.\n",
        "\n",
        "Начнем с очистки данных\n",
        "\n",
        "----------------------------\n",
        "\n",
        "***Внимание!*** Библиотека [*nltk*](https://www.nltk.org) может содержать не все компоненты. В случае возникновения ошибки необходимо запустить скрипт\n",
        "\n",
        "*import nltk   \n",
        "nltk.download()*\n",
        "\n",
        "В открывшемся окне необходимо выбрать и установить требуемые компоненты\n",
        "\n",
        "----------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dF-tFibCcxh6"
      },
      "source": [
        "Приведем весь текст к строчным буквам:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "mXe5Z7Btcxh6"
      },
      "outputs": [],
      "source": [
        "df.text = df.text.str.lower()\n",
        "df.text.loc[19:22]\n",
        "\n",
        "# import nltk\n",
        "# nltk.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dj3naj-cxh8"
      },
      "source": [
        "---\n",
        "\n",
        "Оставим в тексте только русские слова, удалив числа, знаки препинания, специальные символы и слова написанные латиницей:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FuLUqMv5cxh9"
      },
      "outputs": [],
      "source": [
        "df.text = df.text.str.replace(r\"[^А-Яа-я]\",\" \")\n",
        "df.text.loc[19:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he1YbhVvcxh9"
      },
      "source": [
        "---\n",
        "\n",
        "Мы анализируем русскоязычный твиттер, поэтому английские слова, а так же числа, будут представлять частные случаи и формировать шум в данных. Но могут возникнуть задачи, где удаляемые слова и числа важны. В этом случае потребуется более взвешенный подход к очистке. Вам могут помочь [константы модуля *string*](https://docs.python.org/3/library/string.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UuCaIjPScxh-"
      },
      "source": [
        "Разобьем тексты на слова с помощью *word_tokenize*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJA_VuZ5cxh-"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "df.text = list(map(word_tokenize, df.text))\n",
        "df.text.loc[19:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w3LiQIfcxh_"
      },
      "source": [
        "---\n",
        "\n",
        "В каждом языке имеются так называемые стоп-слова - это, например, предлоги, союзы, местоимения и т.д. Стоп-слова не несут смысловой нагрузки, но при этом встречаются достаточно часто. Существует множество словарей стоп-слов, мы воспользуемся словарем библиотеки *nltk*. При решении конкретных задач вы можете как расширить словарь стоп-слов, так и удалить из него любые слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4focLj2Hcxh_"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "russian_stopwords.sort()\n",
        "russian_stopwords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stwsz6MFcxh_"
      },
      "source": [
        "---\n",
        "\n",
        "Удалим стоп-слова из наших данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rGSeR8VNcxiA"
      },
      "outputs": [],
      "source": [
        "def delete_stopword(words):\n",
        "    global russian_stopwords\n",
        "    new_s = [word for word in words if word not in russian_stopwords]\n",
        "    return new_s\n",
        "\n",
        "df.text = list(map(delete_stopword, df.text))\n",
        "df.text.loc[19:22]\n",
        "# df_test.text.loc[0:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2bgmKDkcxiA"
      },
      "source": [
        "---\n",
        "\n",
        "Проведем [лемматизацию](https://ru.wikipedia.org/wiki/Лемматизация) полученных слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00mHnfBdcxiB"
      },
      "outputs": [],
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatization(words):\n",
        "    global morph\n",
        "    new_s = [morph.parse(word)[0].normal_form for word in words]\n",
        "    return new_s\n",
        "\n",
        "df.text = list(map(lemmatization, df.text))\n",
        "df.text.loc[19:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nROxZJjDcxiB"
      },
      "source": [
        "---\n",
        "\n",
        "Теперь необходимо удалить все слова, которые встречаются только 1 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvoyixDGcxiB"
      },
      "outputs": [],
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "def to_str(s):\n",
        "    new_s = ' '.join(j for j in s)\n",
        "    return new_s\n",
        "\n",
        "text_tokens = word_tokenize(' '.join(j for j in list(map(to_str, df.text))))\n",
        "text = nltk.Text(text_tokens)\n",
        "fdist = FreqDist(text)\n",
        "words_to_del = list(filter(lambda k: fdist[k] == 1, fdist))\n",
        "\n",
        "def delete_word(words):\n",
        "    global words_to_del\n",
        "    new_s = [word for word in words if word not in words_to_del]\n",
        "    return new_s\n",
        "\n",
        "df.text = list(map(delete_word, df.text))\n",
        "df.text = list(map(to_str, df.text))\n",
        "df.text.loc[19:22]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J_Ei3tHcxiB"
      },
      "source": [
        "---\n",
        "\n",
        "На этом очистка данных завершена. Можно ли утверждать, что очистка идеальна? Однозначно нет! Но, ее может оказаться достаточно для решения нашей задачи.   \n",
        "Какие еще задачи могут возникнуть при очистке текстовых данных? Вот далеко неполный список:\n",
        "- Обработка больших документов и больших коллекций текстовых документов, которые не помещаются в память.\n",
        "- Извлечение текста из разметки, такой как HTML, PDF или другие структурированные форматы документов.\n",
        "- Транслитерация символов с других языков.\n",
        "- Декодирование символов Юникода в нормализованную форму, такую как UTF8\n",
        "- Обработка доменных имен, фраз и сокращений.\n",
        "- Обработка или удаление чисел, таких как даты и суммы.\n",
        "- Поиск и исправление распространенных опечаток и ошибок в написании.\n",
        "\n",
        "Можно очень долго заниматься очисткой и не достичь идеального результата. Лучше подойти к задаче итеративно - осуществить стандартную очистку и посмотреть на результат, если результат недостаточный, то провести дополнительные мероприятия по очистке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu3rMjvscxiD"
      },
      "outputs": [],
      "source": [
        "len(text_tokens), len(words_to_del), len(text_tokens) - len(words_to_del)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc7MzjibcxiD"
      },
      "source": [
        "---\n",
        "\n",
        "После очистки в наших данных осталось всего 62 слова (это не уникальные повторяющиеся слова, уникальных всего 29). Этого мало для построения классификаторов, но позволило существенно сократить время для знакомства с очисткой данных. В вашем проекте после очистки останется более 1,4 млн слов.\n",
        "\n",
        "\n",
        "После очистки могут оказаться пустые твиты, т.е. эти твиты состояли из слов, записанных латиницей, стоп-слов, чисел, знаков припинания и уникальных слов. Такие твиты необходимо удалить из данных:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVJRoKsdcxiD"
      },
      "outputs": [],
      "source": [
        "len(df[df.text == '']), len(df[(df.text == '') & (df.positive == 1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ_slJtrcxiE"
      },
      "outputs": [],
      "source": [
        "df = df.drop(df[df.text == ''].index, axis = 0)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmtR-PzlcxiE"
      },
      "source": [
        "---\n",
        "\n",
        "После удаления пустых твитов у нас осталось 33 записи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlMO4_7icxiE"
      },
      "source": [
        "----\n",
        "\n",
        "# Задание 2\n",
        "\n",
        "Произведите очистку данных, сформированных в задании 1. По результатам очистки выведите на экран следующую информацию:   \n",
        "- Общее количество слов перед удалением слов, встречающихся 1 раз;\n",
        "- Количество слов, встречающихся 1 раз;\n",
        "- Итоговое количество слов;\n",
        "- Количество пустых твитов;\n",
        "- Из них позитивных твитов;\n",
        "- Количество твитов после удаления пустых.\n",
        "\n",
        "----\n",
        "\n",
        "***Совет:*** сохраняйте промежуточные результаты очистки, чтобы в случае неверных действий на каком-либо этапе не пересчитывать все предыдущие этапы\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = df_all\n",
        "df_test[7:8]"
      ],
      "metadata": {
        "id": "5MscEhIP-E7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.text = df_test.text.str.lower()\n",
        "df_test.text.loc[7:7]"
      ],
      "metadata": {
        "id": "dYjnDirgOnoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df_test.text = df_test.text.str.replace(r\"[^А-Яа-я]\",\" \")\n",
        "df_test.text.loc[0:10]"
      ],
      "metadata": {
        "id": "EhXbFO1gcCnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "df_test.text = list(map(word_tokenize, df_test.text))\n",
        "df_test.text.loc[0:8]"
      ],
      "metadata": {
        "id": "x4G5fkGiQU6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "russian_stopwords = stopwords.words(\"russian\")\n",
        "russian_stopwords.sort()\n",
        "# russian_stopwords"
      ],
      "metadata": {
        "id": "FAVAbuwJcoaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_before = df_test\n",
        "# df_test = df_before"
      ],
      "metadata": {
        "id": "VTaW2gIeDYqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_stopword(words):\n",
        "    global russian_stopwords\n",
        "    new_s = [word for word in words if word not in russian_stopwords]\n",
        "    return new_s\n",
        "\n",
        "df_test.text = list(map(delete_stopword, df_test.text))\n",
        "df_test.text.loc[19:22]\n"
      ],
      "metadata": {
        "id": "IrW0koIRcz2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.text.sum"
      ],
      "metadata": {
        "id": "c8TPqN1TVYHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "\n",
        "def lemmatization(words):\n",
        "    global morph\n",
        "    new_s = [morph.parse(word)[0].normal_form for word in words]\n",
        "    return new_s\n",
        "\n",
        "df_test.text = list(map(lemmatization, df_test.text))\n",
        "df_test.text.loc[0:15]"
      ],
      "metadata": {
        "id": "DGh3TMp4ZXYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Удаление всех слов, которые встречаются только 1 раз:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pplKa-UkaDx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_del = df_test\n",
        "df_del[0:15]"
      ],
      "metadata": {
        "id": "m_2HF-Aof1aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "def to_str(s):\n",
        "    new_s = ' '.join(j for j in s)\n",
        "    return new_s\n",
        "\n",
        "text_tokens = word_tokenize(' '.join(j for j in list(map(to_str, df_del.text))))\n",
        "text = nltk.Text(text_tokens)\n",
        "fdist = FreqDist(text)\n",
        "words_to_del = list(filter(lambda k: fdist[k] == 1, fdist))\n",
        "\n",
        "def delete_word(words):\n",
        "    global words_to_del\n",
        "    new_s = [word for word in words if word not in words_to_del]\n",
        "    return new_s\n",
        "\n",
        "df_del.text = list(map(delete_word, df_del.text))\n",
        "df_del.text = list(map(to_str, df_del.text))\n",
        "df_del.text.loc[0:8]"
      ],
      "metadata": {
        "id": "6xIUSaotZC0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Всего слов: \", len(text_tokens)) \n",
        "print(\"Удалено: \", len(words_to_del))\n",
        "print(\"Осталось слов: \", len(text_tokens) - len(words_to_del))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16SalxaPgGKV",
        "outputId": "df58ba95-0d95-4d4b-9580-ff7c80736767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего слов:  1477000\n",
            "Удалено:  53547\n",
            "Осталось слов:  1423453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Пустых твитов: \", len(df_del[df_del.text == '']))\n",
        "print(\"Из них позитивных: \", len(df_del[(df_del.text == '') & (df_del.positive == 1)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srZatxLcgWM1",
        "outputId": "f1c36278-97b1-4280-83cd-594c806b9de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пустых твитов:  0\n",
            "Из них позитивных:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_after_del = df_del\n",
        "# df_del = df_after_del\n",
        "df_del = df_del.drop(df_del[df_del.text == ''].index, axis = 0)\n",
        "len(df_del)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne-wjGcigd2M",
        "outputId": "2ee09aba-2aa9-4789-bdfd-e9f8900d381b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "225962"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_del[0:15]"
      ],
      "metadata": {
        "id": "mYTZHcp3gmYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svDU8K6fcxiE"
      },
      "source": [
        "Для разработки моделей нам необходимо оцифровать полученные данные. Мы воспользуемся двумя методами: мешком слов [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) и TF-IDF [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). Но в начале необходимо разбить данные на обучающую и тестовую выборки.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvjctSJgcxiE"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.text, df.positive, test_size=0.2, random_state=21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRHONwlncxiF"
      },
      "source": [
        "---\n",
        "\n",
        "Рассмотрим количество твитов в выборке для обучения, из них позитивных, и в выборке для теста, из них позитивных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sCJ_AalcxiF"
      },
      "outputs": [],
      "source": [
        "len(y_train), y_train.sum(), len(y_test), y_test.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozA-Cy-EcxiF"
      },
      "source": [
        "---\n",
        "\n",
        "### Кодировка данных   \n",
        "\n",
        "Кодируем наши данные мешком слов и tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gnjEXNCcxiG"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "cv_train = cv.fit_transform(X_train)\n",
        "cv_test = cv.transform(X_test)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saY0gM8ScxiG"
      },
      "source": [
        "---\n",
        "\n",
        "### Классификаторы\n",
        "\n",
        "Построим классификатор с помощью логистической регрессии:   \n",
        "на основе мешка слов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDuFc9fXcxiG",
        "outputId": "d46d9629-73ce-4553-8a5b-707ef38911cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.70      0.70      0.57         7\n",
            "weighted avg       0.83      0.57      0.57         7\n",
            "\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92        13\n",
            "           1       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.92        26\n",
            "   macro avg       0.92      0.92      0.92        26\n",
            "weighted avg       0.92      0.92      0.92        26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(random_state=21)\n",
        "lr.fit(cv_train, y_train)\n",
        "cv_pred = lr.predict(cv_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, cv_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, lr.predict(cv_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaM2-TmcxiH"
      },
      "source": [
        "---\n",
        "\n",
        "на основе tf-idf:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xG84z4XrcxiH",
        "outputId": "7a051296-0db5-4ebb-f8d3-29fd75877602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.40      0.57         5\n",
            "           1       0.40      1.00      0.57         2\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.70      0.70      0.57         7\n",
            "weighted avg       0.83      0.57      0.57         7\n",
            "\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      1.00      0.96        13\n",
            "           1       1.00      0.92      0.96        13\n",
            "\n",
            "    accuracy                           0.96        26\n",
            "   macro avg       0.96      0.96      0.96        26\n",
            "weighted avg       0.96      0.96      0.96        26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression(random_state=21)\n",
        "lr.fit(tfidf_train, y_train)\n",
        "tfidf_pred = lr.predict(tfidf_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, tfidf_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, lr.predict(tfidf_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFelSBv8cxiH"
      },
      "source": [
        "---\n",
        "\n",
        "Видно, что модели переобучены - это следствие малого количества данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C5MM6FDcxiI"
      },
      "source": [
        "---\n",
        "\n",
        "Построим классификатор с помощью случайного леса [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):   \n",
        "на основе мешка слов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MgSxj3HcxiI",
        "outputId": "7a834e82-99da-452f-8f93-9f513969d990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      1.00      0.91         5\n",
            "           1       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.92      0.75      0.79         7\n",
            "weighted avg       0.88      0.86      0.84         7\n",
            "\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93        13\n",
            "           1       1.00      0.85      0.92        13\n",
            "\n",
            "    accuracy                           0.92        26\n",
            "   macro avg       0.93      0.92      0.92        26\n",
            "weighted avg       0.93      0.92      0.92        26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=3, n_jobs=-1, random_state=21)\n",
        "forest.fit(cv_train, y_train)\n",
        "cv_pred = forest.predict(cv_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, cv_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, forest.predict(cv_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03sG8rNacxiI"
      },
      "source": [
        "---\n",
        "\n",
        "на основе tf-idf:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMJm7XC4cxiI",
        "outputId": "06d16976-2733-4229-8965-543b74da2fee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         5\n",
            "           1       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         7\n",
            "   macro avg       1.00      1.00      1.00         7\n",
            "weighted avg       1.00      1.00      1.00         7\n",
            "\n",
            "train\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92        13\n",
            "           1       0.92      0.92      0.92        13\n",
            "\n",
            "    accuracy                           0.92        26\n",
            "   macro avg       0.92      0.92      0.92        26\n",
            "weighted avg       0.92      0.92      0.92        26\n",
            "\n"
          ]
        }
      ],
      "source": [
        "forest.fit(tfidf_train, y_train)\n",
        "tfidf_pred = forest.predict(tfidf_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, tfidf_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, forest.predict(tfidf_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZJbQ24AcxiJ"
      },
      "source": [
        "---\n",
        "\n",
        "Получили очень хороший результат. Надо проверить, получится ли так же хорошо на всем объеме данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILZT8JtBcxiJ"
      },
      "source": [
        "---\n",
        "\n",
        "# Задание 3\n",
        "\n",
        "1. Кодировать данные методом мешка слов.\n",
        "2. Кодировать данные методом TF-IDF.\n",
        "3. Построить классификатор на основе логистической регрессии, используя мешок слов.\n",
        "4. Построить классификатор на основе логистической регрессии, используя TF-IDF.\n",
        "5. Построить классификатор на основе случайного леса, используя мешок слов.\n",
        "6. Построить классификатор на основе случайного леса, используя TF-IDF.\n",
        "7. Сделайте выводы о разработанных классификаторах.\n",
        "\n",
        "---\n",
        "\n",
        "При разбиении на обучающую и тестовую выборки, следует указать *test_size=0.3*\n",
        "\n",
        "---\n",
        "\n",
        "***Рекомендация:*** для случайного леса параметр n_estimator должен быть не менее 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuQ_OaBzcxiJ"
      },
      "source": [
        "***Рекомендация:*** в чек-листе содержится объемный обучающий материал, поэтому лучше не затягивать с решением заданий"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_del.text, df_del.positive, test_size=0.3, random_state=21)"
      ],
      "metadata": {
        "id": "2yoGDKQchqUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train\n",
        "# y_train"
      ],
      "metadata": {
        "id": "HjZbKCE4vQF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Твитов в выборке для обучения: \", len(y_train))\n",
        "print(\"Из них позитивных: \", y_train.sum())\n",
        "print(\"Твитов в выборке для теста: \", len(y_test))\n",
        "print(\"Из них позитивных: \", y_test.sum())"
      ],
      "metadata": {
        "id": "UkYkuR1HhrpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Кодировка данных\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Кодируем данные мешком слов:"
      ],
      "metadata": {
        "id": "I-aaVIPHwW2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "cv = CountVectorizer()\n",
        "cv_train = cv.fit_transform(X_train)\n",
        "cv_test = cv.transform(X_test)\n",
        "\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_train = tfidf.fit_transform(X_train)\n",
        "tfidf_test = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "4rBPAwS2hy2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=21)\n",
        "lr.fit(cv_train, y_train)\n",
        "cv_pred = lr.predict(cv_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, cv_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, lr.predict(cv_train)))"
      ],
      "metadata": {
        "id": "C-ay0W21h9uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кодируем данные tf-idf:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PJTdI_BuwxEz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(random_state=21)\n",
        "lr.fit(tfidf_train, y_train)\n",
        "tfidf_pred = lr.predict(tfidf_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, tfidf_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, lr.predict(tfidf_train)))"
      ],
      "metadata": {
        "id": "MTBm1dVPiG38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Классификатор с помощью случайного леса RandomForestClassifier:\n",
        "на основе мешка слов:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "RI2vbR0CiN0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "forest = RandomForestClassifier(n_estimators=200, n_jobs=-1, random_state=21)\n",
        "forest.fit(cv_train, y_train)\n",
        "cv_pred = forest.predict(cv_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, cv_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, forest.predict(cv_train)))"
      ],
      "metadata": {
        "id": "4OC0iiBjiMiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "на основе tf-idf:\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "JJBrAmFxicTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "forest.fit(tfidf_train, y_train)\n",
        "tfidf_pred = forest.predict(tfidf_test)\n",
        "print('test')\n",
        "print(classification_report(y_test, tfidf_pred))\n",
        "print('train')\n",
        "print(classification_report(y_train, forest.predict(tfidf_train)))"
      ],
      "metadata": {
        "id": "GEFyvzKLijAh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "d05_desk.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}