## Обработка текстовых данных 2
В рамках этого дня я освоил более продвинутые способы работы с текстовыми данными.

Сегодня я изучил более сложную модель векторизации текстов - word2vec - которая преобразует тексты в числовые векторы фиксированной длины, учитывая контекст слов в них.

Также вы изучите еще один классификатор, основанный на уже известных вам решающих деревьях. Это градиентный бустинг над решающими деревьями. Его особенность заключается в том, что это не просто ансамбль деревьев, как случайный лес, но еще и модель, которая сама предсказывает свои ошибки и сразу пытается их корректировать.

### Цели

Наша цель - научиться использовать word2vec, научиться работать с градиентным бустингом, а также расширить арсенал используемых библиотек для машинного обучения.

### Задание

Что нужно сделать:
1. Проведите предобработку текстов. Создайте несколько моделей word2vec с параметрами, указанными в блокноте. Обучите их на всём пространстве текстов. Найдите по 15 синонимов и антонимов для 5 случайных слов из каждой из подвыборок позитивных и негативных твитов. Опишите, как влияет размер результирующего пространства и параметр минимальной встречаемости слов в выборке на нахождение синонимов. Постройте графики распределения слов в двумерном пространстве с помощью метода t-SNE и опишите, как влияют параметры модели на расположение точек на графике. Предскажите продолжение твита обученной с параметрами по умолчанию моделью w2v. Сравните результаты, полученные после обучения моделей с разным количеством эпох обучения.
2. Проведите классификацию текстов с помощью векторизатора doc2vec и градиентного бустинга над решающими деревьями. Подберите гиперпараметры моделей: минимальную встречаемость слова в текстах doc2vec, максимальную глубину деревьев бустинга, количество деревьев в бустинге.
